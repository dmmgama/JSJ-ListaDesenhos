import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import google.generativeai as genai
from PIL import Image
import io
import json
import time
import asyncio
from collections import deque
import tempfile
import os
import logging
import re
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4, landscape
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import cm
from reportlab.lib.enums import TA_CENTER, TA_LEFT
from datetime import datetime

try:
    import ezdxf
    from ezdxf.addons.drawing import RenderContext, Frontend
    from ezdxf.addons.drawing.matplotlib import MatplotlibBackend
    import matplotlib
    matplotlib.use('Agg')  # Backend sem GUI
    import matplotlib.pyplot as plt
    DWG_SUPPORT = True
except ImportError:
    DWG_SUPPORT = False

# --- CONFIGURA√á√ÉO DE LOGGING ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('jsj_parser.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- FUN√á√ÉO DE VALIDA√á√ÉO DE DADOS ---
def validate_extracted_data(data, filename=""):
    """Valida dados extra√≠dos pela IA para garantir integridade.

    Retorna: (is_valid: bool, errors: list, warnings: list)
    """
    errors = []
    warnings = []

    # 1. Validar n√∫mero de desenho (obrigat√≥rio e n√£o vazio)
    num_desenho = data.get('num_desenho', '').strip()
    if not num_desenho or num_desenho == 'ERRO':
        errors.append("N√∫mero de desenho vazio ou inv√°lido")
    elif len(num_desenho) < 3:
        warnings.append(f"N√∫mero de desenho muito curto: '{num_desenho}'")

    # 2. Validar data (formato DD/MM/YYYY ou varia√ß√µes comuns)
    data_str = data.get('data', '').strip()
    if data_str:
        # Aceitar formatos: DD/MM/YYYY, DD-MM-YYYY, DD.MM.YYYY
        date_patterns = [
            r'^\d{2}[/\-\.]\d{2}[/\-\.]\d{4}$',  # DD/MM/YYYY
            r'^\d{1}[/\-\.]\d{2}[/\-\.]\d{4}$',  # D/MM/YYYY
            r'^\d{2}[/\-\.]\d{1}[/\-\.]\d{4}$',  # DD/M/YYYY
        ]

        if not any(re.match(pattern, data_str) for pattern in date_patterns):
            # Verificar se n√£o √© placeholder comum
            if data_str.lower() in ['n/d', 'n/a', '?', '??/??/????', 'ileg√≠vel']:
                warnings.append(f"Data ileg√≠vel ou n√£o dispon√≠vel: '{data_str}'")
            else:
                errors.append(f"Formato de data inv√°lido: '{data_str}' (esperado DD/MM/YYYY)")
        else:
            # Validar valores num√©ricos
            parts = re.split(r'[/\-\.]', data_str)
            if len(parts) == 3:
                dia, mes, ano = parts
                try:
                    dia_int, mes_int, ano_int = int(dia), int(mes), int(ano)
                    if not (1 <= dia_int <= 31):
                        errors.append(f"Dia inv√°lido: {dia_int}")
                    if not (1 <= mes_int <= 12):
                        errors.append(f"M√™s inv√°lido: {mes_int}")
                    if not (2000 <= ano_int <= 2100):
                        warnings.append(f"Ano fora do range esperado: {ano_int}")
                except ValueError:
                    errors.append(f"Data cont√©m valores n√£o num√©ricos: '{data_str}'")
    else:
        warnings.append("Data vazia")

    # 3. Validar revis√£o (letra A-Z mai√∫scula ou '0' para primeira emiss√£o)
    revisao = data.get('revisao', '').strip()
    if revisao:
        if not re.match(r'^[A-Z0]$', revisao):
            # Aceitar tamb√©m min√∫sculas e converter
            if re.match(r'^[a-z]$', revisao):
                warnings.append(f"Revis√£o em min√∫scula: '{revisao}' (esperado mai√∫scula)")
            else:
                errors.append(f"Revis√£o inv√°lida: '{revisao}' (esperado letra A-Z ou '0')")
    else:
        warnings.append("Revis√£o vazia")

    # 4. Validar t√≠tulo (opcional mas recomendado)
    titulo = data.get('titulo', '').strip()
    if not titulo:
        warnings.append("T√≠tulo vazio")
    elif len(titulo) < 3:
        warnings.append(f"T√≠tulo muito curto: '{titulo}'")

    # 5. Verificar se h√° erro reportado pela pr√≥pria IA
    if 'error' in data:
        errors.append(f"IA reportou erro: {data['error']}")

    is_valid = len(errors) == 0

    # Log de valida√ß√£o
    if errors:
        logger.error(f"Valida√ß√£o FALHOU para {filename}: {errors}")
    if warnings:
        logger.warning(f"Valida√ß√£o com avisos para {filename}: {warnings}")
    if is_valid and not warnings:
        logger.info(f"Valida√ß√£o OK para {filename}: Rev={revisao}, Data={data_str}")

    return is_valid, errors, warnings

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="JSJ Parser v2 (Unified)",
    page_icon="üèóÔ∏è",
    layout="wide"
)

# --- INICIALIZA√á√ÉO DO ESTADO (MEM√ìRIA TEMPOR√ÅRIA) ---
if 'master_data' not in st.session_state:
    st.session_state.master_data = []
if 'total_tokens' not in st.session_state:
    st.session_state.total_tokens = 0
if 'ordem_customizada' not in st.session_state:
    st.session_state.ordem_customizada = []
if 'crop_validated' not in st.session_state:
    st.session_state.crop_validated = False
if 'pending_tasks' not in st.session_state:
    st.session_state.pending_tasks = None
if 'should_process' not in st.session_state:
    st.session_state.should_process = False

# --- BARRA LATERAL (CONFIGURA√á√ÉO) ---
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√£o")
    api_key = st.text_input("Google Gemini API Key", type="password")

    # Modo TURBO (unifica jsj_app.py e jsjturbo.py)
    turbo_mode = st.checkbox(
        "üöÄ Modo TURBO (Paid Tier)",
        value=False,
        help="Aumenta rate limit de 15 para 1000 req/min e batch size de 5 para 50. Requer conta Google Cloud paga."
    )

    if turbo_mode:
        st.info("‚ö° Modo TURBO ativo: 1000 req/min, batch 50")
    else:
        st.info("üê¢ Modo Standard: 15 req/min, batch 5")

    st.divider()

    # Configura√ß√£o de Crop (Prioridade 3)
    st.subheader("‚úÇÔ∏è √Årea de Crop")
    crop_preset = st.selectbox(
        "Posi√ß√£o da Legenda",
        [
            "Canto Inf. Direito (50%)",
            "Canto Inf. Direito (40%)",
            "Canto Inf. Direito (30%)",
            "Canto Inf. Direito (70%)",
            "Metade Inferior (100% largura)",
            "P√°gina Inteira"
        ],
        index=0,
        help="Define que parte da p√°gina ser√° analisada pela IA"
    )

    # Mostrar preview do crop
    show_crop_preview = st.checkbox(
        "üëÅÔ∏è Validar crop antes de processar",
        value=False,
        help="Mostra preview do crop para valida√ß√£o antes de processar (recomendado para primeiro uso)"
    )

    st.divider()

    # PAINEL DE LOTES CARREGADOS
    st.subheader("üì¶ Lotes em Mem√≥ria")
    if len(st.session_state.master_data) > 0:
        # Agrupar por TIPO e contar
        df_temp = pd.DataFrame(st.session_state.master_data)
        summary = df_temp.groupby('TIPO').size().sort_index()

        for tipo, count in summary.items():
            st.metric(label=tipo, value=f"{count} desenhos")

        st.caption(f"**Total:** {len(st.session_state.master_data)} desenhos")
    else:
        st.info("Nenhum lote carregado ainda.")

    st.divider()
    st.caption("A tabela de revis√µes visual √© a fonte de verdade.")
    
    # CONTADOR DE TOKENS E CUSTO
    if st.session_state.total_tokens > 0:
        st.divider()
        st.subheader("üí∞ Custo Estimado")
        # Gemini Flash 2.5: $0.075 / 1M tokens input, $0.30 / 1M tokens output
        # Estimativa conservadora: 70% input, 30% output
        input_tokens = st.session_state.total_tokens * 0.7
        output_tokens = st.session_state.total_tokens * 0.3
        custo_usd = (input_tokens * 0.075 / 1_000_000) + (output_tokens * 0.30 / 1_000_000)
        custo_eur = custo_usd * 0.95  # Convers√£o aproximada USD->EUR
        
        st.metric("Tokens Usados", f"{st.session_state.total_tokens:,}")
        st.metric("Custo Estimado", f"‚Ç¨{custo_eur:.4f}")
        st.caption(f"‚âà ${custo_usd:.4f} USD")

    st.divider()

    if st.button("üóëÔ∏è Limpar Toda a Mem√≥ria", type="primary"):
        st.session_state.master_data = []
        st.session_state.total_tokens = 0
        st.session_state.ordem_customizada = []
        st.rerun()

# --- FUN√á√ïES DE PROCESSAMENTO (BACKEND) ---

class RateLimiter:
    """Rate limiter inteligente para respeitar limites da API Gemini.

    Gemini Flash v2.5/v2.0: 15 requests/minuto
    Implementa sliding window para m√°xima efici√™ncia.
    """
    def __init__(self, max_requests=15, time_window=60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = deque()

    async def acquire(self):
        """Aguarda at√© que seja seguro fazer um novo request."""
        now = time.time()

        # Remove requests antigos fora da janela
        while self.requests and self.requests[0] < now - self.time_window:
            self.requests.popleft()

        # Se atingiu o limite, espera o tempo m√≠nimo necess√°rio
        if len(self.requests) >= self.max_requests:
            sleep_time = self.requests[0] + self.time_window - now + 0.1
            await asyncio.sleep(sleep_time)
            return await self.acquire()  # Re-check ap√≥s espera

        # Registra o novo request
        self.requests.append(now)

def get_crop_coordinates(preset, rect):
    """Calcula as coordenadas de crop baseadas no preset selecionado.

    Args:
        preset: String com o preset selecionado
        rect: fitz.Rect da p√°gina

    Returns:
        tuple: (x_start_pct, y_start_pct, x_end_pct, y_end_pct) em percentagens
    """
    if preset == "Canto Inf. Direito (50%)":
        return (0.50, 0.50, 1.0, 1.0)  # Quadrante inferior direito (padr√£o)
    elif preset == "Canto Inf. Direito (40%)":
        return (0.60, 0.60, 1.0, 1.0)  # 40% da √°rea (60% offset)
    elif preset == "Canto Inf. Direito (30%)":
        return (0.70, 0.70, 1.0, 1.0)  # √Årea menor, mais focada
    elif preset == "Canto Inf. Direito (70%)":
        return (0.30, 0.30, 1.0, 1.0)  # √Årea maior
    elif preset == "Metade Inferior (100% largura)":
        return (0.0, 0.50, 1.0, 1.0)  # Toda a metade inferior
    elif preset == "P√°gina Inteira":
        return (0.0, 0.0, 1.0, 1.0)  # P√°gina completa
    else:
        return (0.50, 0.50, 1.0, 1.0)  # Padr√£o

def get_image_from_page(doc, page_num, crop_preset="Canto Inf. Direito (50%)"):
    """Extrai a imagem (crop da legenda) de uma p√°gina espec√≠fica do documento.

    Args:
        doc: Documento PyMuPDF
        page_num: N√∫mero da p√°gina
        crop_preset: Preset de crop selecionado

    Returns:
        PIL.Image: Imagem extra√≠da
    """
    page = doc.load_page(page_num)
    rect = page.rect

    # Calcular coordenadas do crop
    x_start, y_start, x_end, y_end = get_crop_coordinates(crop_preset, rect)

    crop_rect = fitz.Rect(
        rect.width * x_start,
        rect.height * y_start,
        rect.width * x_end,
        rect.height * y_end
    )

    logger.debug(f"Crop preset '{crop_preset}': ({x_start:.0%}, {y_start:.0%}) -> ({x_end:.0%}, {y_end:.0%})")

    pix = page.get_pixmap(clip=crop_rect, matrix=fitz.Matrix(2, 2)) # 2x zoom para clareza
    img_data = pix.tobytes("png")

    return Image.open(io.BytesIO(img_data))

def extract_dwg_native_blocks(dwg_path, layout_name):
    """Extrai dados nativos de TODOS os blocos LEGENDA_JSJ_V1 num layout.
    
    Retorna: list[dict] com dados extra√≠dos de cada bloco encontrado.
             Lista vazia se n√£o houver blocos LEGENDA ou se falhar.
    """
    if not DWG_SUPPORT:
        return []
    
    try:
        doc = ezdxf.readfile(dwg_path)
        
        # Obter layout
        if layout_name == 'Model':
            layout = doc.modelspace()
        else:
            layout = doc.paperspace(layout_name)
        
        # Procurar TODOS os INSERTs de blocos com "LEGENDA" no nome
        inserts = [i for i in layout.query('INSERT') if "LEGENDA" in i.dxf.name.upper()]
        
        if not inserts:
            logger.info(f"Nenhum bloco LEGENDA encontrado em {layout_name}")
            return []
        
        logger.info(f"Encontrados {len(inserts)} blocos LEGENDA em {layout_name}")
        
        extracted_blocks = []
        
        for insert_idx, insert in enumerate(inserts):
            try:
                # Converter lista de atributos para dict
                attribs_dict = {a.dxf.tag: a.dxf.text for a in insert.attribs}
                
                # Extrair campos diretos
                tipo = attribs_dict.get('TIPO', '').strip()
                num_desenho = attribs_dict.get('DES_NUM', '').strip()
                titulo = attribs_dict.get('TITULO', '').strip()
                primeira_emissao = attribs_dict.get('DATA', '').strip()  # Data base (1¬™ Emiss√£o)
                
                # HIST√ìRICO DE REVIS√ïES: Verificar ordem crescente A‚ÜíE, guardar a √öLTIMA (mais avan√ßada)
                revisao_letra = ''
                revisao_data = ''
                revisao_desc = ''
                
                for rev in ['A', 'B', 'C', 'D', 'E']:
                    rev_tag = attribs_dict.get(f'REV_{rev}', '').strip()
                    if rev_tag:  # Tag REV_* n√£o vazia ‚Üí atualizar (√∫ltima sobrescreve)
                        revisao_letra = rev
                        revisao_data = attribs_dict.get(f'DATA_{rev}', '').strip()
                        revisao_desc = attribs_dict.get(f'DESC_{rev}', '').strip()
                # Resultado: revisao_letra cont√©m a letra mais avan√ßada no alfabeto
                
                # Validar se tem dados m√≠nimos
                if not num_desenho and not titulo:
                    logger.warning(f"Bloco {insert_idx+1} em {layout_name}: campos vazios, ignorado")
                    continue
                
                extracted_blocks.append({
                    'tipo': tipo or 'N/A',
                    'num_desenho': num_desenho or 'N/A',
                    'titulo': titulo or 'Sem t√≠tulo',
                    'primeira_emissao': primeira_emissao or 'N/A',
                    'revisao': revisao_letra,           # Vazio se sem revis√µes
                    'data_revisao': revisao_data,       # Vazio se sem revis√µes
                    'desc_revisao': revisao_desc,       # Vazio se sem revis√µes
                    'obs': 'Extra√ß√£o nativa (zero custo)'
                })
                
                logger.info(f"Bloco {insert_idx+1}: {num_desenho} - Rev {revisao_letra if revisao_letra else '(1¬™ Emiss√£o)'}")
                
            except Exception as e:
                logger.error(f"Erro ao extrair bloco {insert_idx+1} em {layout_name}: {e}")
                continue
        
        return extracted_blocks
        
    except Exception as e:
        logger.error(f"Erro na extra√ß√£o nativa de {layout_name}: {e}")
        return []

def get_image_from_dwg_layout(dwg_path, layout_name):
    """Extrai imagem de um layout espec√≠fico de um ficheiro DWG."""
    if not DWG_SUPPORT:
        raise ImportError("ezdxf n√£o est√° instalado. Instala com: pip install ezdxf matplotlib")
    
    try:
        # Carregar o DWG/DXF
        doc = ezdxf.readfile(dwg_path)
        
        # Obter o layout
        if layout_name == 'Model':
            msp = doc.modelspace()
            layout = msp
        else:
            layout = doc.paperspace(layout_name)
        
        # Configurar figura com fundo branco
        fig = plt.figure(figsize=(16, 12), dpi=200, facecolor='white')
        ax = fig.add_axes([0, 0, 1, 1])
        ax.set_facecolor('white')
        
        # Configurar contexto de renderiza√ß√£o
        ctx = RenderContext(doc)
        out = MatplotlibBackend(ax)
        
        # Renderizar o layout
        Frontend(ctx, out).draw_layout(layout, finalize=True)
        
        # Ajustar limites do gr√°fico
        ax.autoscale()
        ax.margins(0.05)
        
        # Converter para bytes
        buf = io.BytesIO()
        fig.savefig(buf, format='png', bbox_inches='tight', dpi=200, facecolor='white')
        buf.seek(0)
        plt.close(fig)
        
        # Carregar imagem completa
        img = Image.open(buf)
        width, height = img.size
        
        # CROP: Quadrante inferior direito (50% x 50%)
        crop_box = (
            width // 2,      # left (50% da largura)
            height // 2,     # top (50% da altura)
            width,           # right (100%)
            height           # bottom (100%)
        )
        
        cropped = img.crop(crop_box)
        
        # Garantir que a imagem est√° em RGB
        if cropped.mode != 'RGB':
            cropped = cropped.convert('RGB')
        
        return cropped
        
    except Exception as e:
        raise Exception(f"Erro ao processar DWG layout '{layout_name}': {str(e)}")

def get_dwg_layouts(dwg_path):
    """Retorna lista de nomes de layouts Paper Space num ficheiro DWG.

    Model Space √© ignorado conforme Regra de Ouro #4 (Multi-Layout).
    Retorna lista vazia se s√≥ existir Model Space.
    """
    if not DWG_SUPPORT:
        return []

    try:
        doc = ezdxf.readfile(dwg_path)

        # Obter APENAS paperspace layouts (ignora Model Space)
        paperspace_layouts = []
        for layout in doc.layouts:
            if layout.name != 'Model':
                paperspace_layouts.append(layout.name)

        # Se n√£o houver paperspace layouts, retorna VAZIO (n√£o processar Model)
        # O c√≥digo chamador deve avisar o utilizador
        if not paperspace_layouts:
            logger.warning(f"DWG sem Paper Space layouts: {dwg_path}")
            return []

        return sorted(paperspace_layouts)

    except Exception as e:
        logger.error(f"Erro ao ler layouts DWG {dwg_path}: {e}")
        return []

def create_pdf_export(df):
    """Cria PDF profissional com a lista de desenhos."""
    buffer = io.BytesIO()
    
    # Configurar documento em landscape A4
    doc = SimpleDocTemplate(
        buffer,
        pagesize=landscape(A4),
        rightMargin=1.5*cm,
        leftMargin=1.5*cm,
        topMargin=2*cm,
        bottomMargin=2*cm
    )
    
    # Estilos
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=18,
        textColor=colors.HexColor('#1f4788'),
        spaceAfter=20,
        alignment=TA_CENTER,
        fontName='Helvetica-Bold'
    )
    
    subtitle_style = ParagraphStyle(
        'CustomSubtitle',
        parent=styles['Heading2'],
        fontSize=14,
        textColor=colors.HexColor('#2c5aa0'),
        spaceAfter=12,
        spaceBefore=12,
        fontName='Helvetica-Bold'
    )
    
    # Elementos do documento
    elements = []
    
    # Cabe√ßalho
    elements.append(Paragraph("LISTA DE DESENHOS JSJ", title_style))
    elements.append(Paragraph(f"Gerado em {datetime.now().strftime('%d/%m/%Y √†s %H:%M')}", styles['Normal']))
    elements.append(Spacer(1, 0.5*cm))
    
    # Processar por tipo
    for tipo in df['TIPO'].unique():
        df_tipo = df[df['TIPO'] == tipo]
        
        # Subt√≠tulo do tipo
        elements.append(Paragraph(f"TIPO: {tipo}", subtitle_style))
        elements.append(Spacer(1, 0.3*cm))
        
        # Preparar dados da tabela
        table_data = [['N¬∫ Desenho', 'T√≠tulo', 'Rev', 'Data', 'Ficheiro', 'Obs']]
        
        for _, row in df_tipo.iterrows():
            table_data.append([
                str(row['Num. Desenho']),
                str(row['Titulo'])[:50] + '...' if len(str(row['Titulo'])) > 50 else str(row['Titulo']),
                str(row['Revis√£o']),
                str(row['Data']),
                str(row['Ficheiro'])[:30] + '...' if len(str(row['Ficheiro'])) > 30 else str(row['Ficheiro']),
                str(row['Obs'])[:30] + '...' if len(str(row['Obs'])) > 30 else str(row['Obs'])
            ])
        
        # Criar tabela
        table = Table(table_data, colWidths=[3.5*cm, 6*cm, 1.5*cm, 2*cm, 5*cm, 4*cm])
        
        # Estilo da tabela
        table.setStyle(TableStyle([
            # Cabe√ßalho
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1f4788')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, 0), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            
            # Dados
            ('BACKGROUND', (0, 1), (-1, -1), colors.white),
            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),
            ('ALIGN', (0, 1), (-1, -1), 'LEFT'),
            ('ALIGN', (2, 1), (3, -1), 'CENTER'),  # Rev e Data centralizadas
            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 1), (-1, -1), 8),
            ('TOPPADDING', (0, 1), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 1), (-1, -1), 6),
            
            # Linhas alternadas
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f0f4f8')]),
            
            # Bordas
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#cccccc')),
            ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#1f4788')),
            
            # Alinhamento vertical
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))
        
        elements.append(table)
        elements.append(Spacer(1, 0.8*cm))
        
        # Page break entre tipos (exceto √∫ltimo)
        if tipo != df['TIPO'].unique()[-1]:
            elements.append(PageBreak())
    
    # Rodap√©
    elements.append(Spacer(1, 1*cm))
    footer_text = f"Total de desenhos: {len(df)} | Tipos: {', '.join(df['TIPO'].unique())}"
    elements.append(Paragraph(footer_text, styles['Italic']))
    
    # Gerar PDF
    doc.build(elements)
    buffer.seek(0)
    
    return buffer

async def ask_gemini_async(image, file_context, rate_limiter, api_key_param):
    """O C√©rebro Ass√≠ncrono: Processa requests em paralelo com rate limiting.

    Args:
        image: Imagem PIL para an√°lise
        file_context: Nome do ficheiro (para logging)
        rate_limiter: Inst√¢ncia de RateLimiter
        api_key_param: API key do Google Gemini

    Returns:
        dict: Dados extra√≠dos pela IA
    """
    if not api_key_param:
        logger.error("Tentativa de processar sem API Key")
        return {"error": "Sem API Key", "num_desenho": "ERRO", "titulo": file_context, "revisao": "?", "data": "??/??/????", "obs": "API Key n√£o fornecida"}, 0

    # Aguarda permiss√£o do rate limiter
    await rate_limiter.acquire()

    # Executa a chamada s√≠ncrona da API em thread separada
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, _ask_gemini_sync, image, file_context, api_key_param)

def _ask_gemini_sync(image, file_context, api_key_param):
    """Wrapper s√≠ncrono para chamada ao Gemini (executado em thread pool).

    Args:
        image: Imagem PIL para an√°lise
        file_context: Nome do ficheiro (para logging)
        api_key_param: API key do Google Gemini

    Returns:
        tuple: (dados_extraidos: dict, tokens_usados: int)
    """
    genai.configure(api_key=api_key_param)

    # LISTA DE MODELOS ATUALIZADA
    models_to_try = [
        'gemini-2.5-flash',          # PRIORIDADE 1
        'gemini-2.0-flash',          # PRIORIDADE 2
        'gemini-1.5-flash',          # Fallback Standard
        'gemini-1.5-flash-latest',   # Fallback Alias
        'gemini-pro'                 # Legacy
    ]

    prompt = """
    √âs um t√©cnico de documenta√ß√£o especializado em extrair metadados de desenhos t√©cnicos. Analisa APENAS o que est√° visualmente desenhado/escrito nesta imagem.

    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë REGRA DE OURO #1: IGNORA COMPLETAMENTE O NOME DO FICHEIRO        ‚ïë
    ‚ïë REGRA DE OURO #2: A TABELA DE REVIS√ïES √â A FONTE DA VERDADE      ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

    üìã PASSO A PASSO (SEGUE RIGOROSAMENTE):

    1Ô∏è‚É£ LOCALIZAR A LEGENDA (geralmente canto inferior direito):
       - Procura o campo "N¬∫ DESENHO" ou "DESENHO N¬∫" ou similar
       - Extrai o N√öMERO escrito nesse campo (ex: "2025-EST-001")
       - Extrai o T√çTULO do desenho

    2Ô∏è‚É£ LOCALIZAR A TABELA DE REVIS√ïES (geralmente acima da legenda):
       - Procura uma TABELA com colunas tipo: REV | DATA | DESCRI√á√ÉO/ALTERA√á√ÉO
       - Formato comum: linhas horizontais com c√©lulas preenchidas
       - Pode estar dentro de um rect√¢ngulo/moldura separada

    3Ô∏è‚É£ IDENTIFICAR A REVIS√ÉO MAIS RECENTE:
       ‚ö†Ô∏è ATEN√á√ÉO: Esta √© a parte MAIS IMPORTANTE!

       SE a tabela tem linhas preenchidas (ex: A, B, C):
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ REV ‚îÇ   DATA    ‚îÇ      ALTERA√á√ÉO           ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ  A  ‚îÇ 10/01/2025‚îÇ Primeira emiss√£o         ‚îÇ ‚Üê N√ÉO usar esta
       ‚îÇ  B  ‚îÇ 15/02/2025‚îÇ Correc√ß√£o de medidas     ‚îÇ ‚Üê N√ÉO usar esta
       ‚îÇ  C  ‚îÇ 20/03/2025‚îÇ Ajuste de armaduras      ‚îÇ ‚Üê USAR ESTA! ‚úì
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

       ‚Üí A revis√£o mais recente √© "C" (letra mais avan√ßada)
       ‚Üí A data a extrair √© "20/03/2025" (data da LINHA C)
       ‚Üí üö´ N√ÉO USES a data base da legenda!
       ‚Üí üö´ N√ÉO USES a data do campo "DATA:" da legenda principal!

       SE a tabela estiver COMPLETAMENTE VAZIA (sem linhas preenchidas):
       ‚Üí Revis√£o = "0" (primeira emiss√£o)
       ‚Üí Neste caso SIM, usa a data base do campo "DATA:" da legenda principal

    4Ô∏è‚É£ VALIDA√á√ÉO FINAL:
       - Confirma que a data extra√≠da corresponde √† linha da revis√£o mais avan√ßada
       - Se houver d√∫vida, menciona na obs

    üì§ RETORNA APENAS JSON V√ÅLIDO (sem coment√°rios):
    {
        "num_desenho": "string - N√∫mero escrito no campo da legenda",
        "titulo": "string - T√≠tulo do desenho",
        "revisao": "string - Letra mais avan√ßada da tabela OU '0' se vazia",
        "data": "string - Data DD/MM/YYYY da LINHA dessa revis√£o (ou data base se Rev 0)",
        "obs": "string - Avisos se ileg√≠vel/em falta, sen√£o vazio"
    }

    ‚ö†Ô∏è VERIFICA√á√ÉO: Antes de retornar, confirma mentalmente:
    - "A data que estou a retornar vem da LINHA da revis√£o mais recente?"
    - "Ou vem do campo DATA base porque a tabela est√° vazia?"
    """

    last_error = ""
    last_model = ""

    # LOOP DE TENTATIVAS (ROBUST FALLBACK)
    for model_name in models_to_try:
        try:
            logger.info(f"Tentando modelo {model_name} para {file_context}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content([prompt, image])
            last_model = model_name

            # Se chegou aqui, a chamada √† API funcionou!
            clean_text = response.text.replace("```json", "").replace("```", "").strip()

            # Contabilizar tokens (estimativa)
            if hasattr(response, 'usage_metadata'):
                total = response.usage_metadata.total_token_count
            else:
                # Estimativa se n√£o houver metadata: ~500 tokens por request
                total = 500

            # *** VALIDA√á√ÉO ROBUSTA DO JSON ***
            try:
                parsed_data = json.loads(clean_text)
            except json.JSONDecodeError as e:
                logger.error(f"JSON inv√°lido retornado pela IA para {file_context}: {e}")
                logger.debug(f"Resposta bruta: {clean_text[:200]}...")
                return {
                    "error": f"IA retornou JSON malformado: {str(e)}",
                    "num_desenho": "ERRO_JSON",
                    "titulo": file_context,
                    "revisao": "?",
                    "data": "??/??/????",
                    "obs": f"Erro de parsing JSON: {str(e)}"
                }, 0

            # *** VALIDA√á√ÉO DE INTEGRIDADE DOS DADOS ***
            is_valid, errors, warnings = validate_extracted_data(parsed_data, file_context)

            if not is_valid:
                # Dados inv√°lidos - reportar mas n√£o falhar completamente
                logger.error(f"Dados inv√°lidos extra√≠dos de {file_context}: {errors}")
                parsed_data['obs'] = f"VALIDA√á√ÉO FALHOU: {'; '.join(errors)}"
                if warnings:
                    parsed_data['obs'] += f" | Avisos: {'; '.join(warnings)}"
            elif warnings:
                # Dados v√°lidos mas com avisos
                if parsed_data.get('obs'):
                    parsed_data['obs'] += f" | {'; '.join(warnings)}"
                else:
                    parsed_data['obs'] = '; '.join(warnings)

            logger.info(f"Sucesso com modelo {model_name} para {file_context} ({total} tokens)")
            return parsed_data, total

        except Exception as e:
            last_error = str(e)
            logger.warning(f"Modelo {model_name} falhou para {file_context}: {last_error}")
            continue

    # Se chegou aqui, todos os modelos falharam
    logger.error(f"TODOS os modelos falharam para {file_context}. √öltimo erro: {last_error}")
    return {
        "error": f"Falha IA. √öltimo erro: {last_error}",
        "num_desenho": "ERRO",
        "titulo": file_context,
        "revisao": "?",
        "data": "??/??/????",
        "obs": f"Todos os modelos falharam. √öltimo modelo: {last_model or 'nenhum'}"
    }, 0

# --- INTERFACE PRINCIPAL (FRONTEND) ---

st.title("üèóÔ∏è Gestor de Desenhos JSJ")
st.markdown("---")

col_input, col_view = st.columns([1, 2])

with col_input:
    st.subheader("1. Novo Lote")
    
    # Seletor de tipo com op√ß√µes predefinidas
    tipo_preset = st.selectbox(
        "üè∑Ô∏è Tipo de Desenho",
        [
            "Dimensionamento",
            "Bet√£o Armado - Lajes",
            "Bet√£o Armado - Pilares",
            "Bet√£o Armado - Funda√ß√µes",
            "Bet√£o Armado - Vigas",
            "Bet√£o Armado - N√∫cleos",
            "Pr√©-esfor√ßo",
            "Custom (personalizado)"
        ],
        index=0,
        help="Seleciona o tipo ou escolhe 'Custom' para inserir manualmente"
    )
    
    # Input manual se "Custom" selecionado
    if tipo_preset == "Custom (personalizado)":
        batch_type = st.text_input(
            "‚úèÔ∏è Tipo Personalizado", 
            placeholder="Ex: METALICA, PORMENOR...",
            help="Insere o tipo personalizado"
        )
    else:
        batch_type = tipo_preset
    
    # Tipos de ficheiro suportados
    file_types = ["pdf"]
    if DWG_SUPPORT:
        file_types.extend(["dwg", "dxf"])
        st.caption("‚úÖ Suporte DWG/DXF ativo")
    else:
        st.caption("‚ö†Ô∏è Instala ezdxf para suportar DWG: `pip install ezdxf matplotlib`")
    
    # Inicializar key do uploader se n√£o existir
    if 'uploader_key' not in st.session_state:
        st.session_state.uploader_key = 0
    
    uploaded_files = st.file_uploader(
        "üìÑ Carregar Ficheiros", 
        type=file_types, 
        accept_multiple_files=True,
        help="Suporta PDF e DWG/DXF (cada layout = 1 desenho)",
        key=f"file_uploader_{st.session_state.uploader_key}"
    )
    
    # Bot√£o de processar
    process_btn = st.button("‚ö° Processar Lote", disabled=(not uploaded_files or not batch_type))

    # L√ìGICA DE VALIDA√á√ÉO DE CROP
    # Se checkbox N√ÉO marcada ‚Üí processa diretamente
    # Se checkbox MARCADA ‚Üí mostra preview e pede valida√ß√£o

    if process_btn:
        if not api_key:
            st.error("‚ö†Ô∏è Falta a API Key na barra lateral!")
        elif not show_crop_preview:
            # Processar diretamente sem valida√ß√£o
            st.session_state.crop_validated = True
            st.session_state.should_process = True
            st.session_state.pending_tasks = uploaded_files
            st.rerun()
        else:
            # Mostrar preview do crop do primeiro desenho para valida√ß√£o
            st.info("### ‚úÇÔ∏è Valida√ß√£o de Crop")
            st.caption("Valida a √°rea de crop antes de processar todos os desenhos")

            # Extrair primeira p√°gina do primeiro ficheiro para preview
            first_file = uploaded_files[0]
            file_ext = first_file.name.lower().split('.')[-1]

            try:
                if file_ext == 'pdf':
                    bytes_data = first_file.read()
                    doc = fitz.open(stream=bytes_data, filetype="pdf")
                    preview_img = get_image_from_page(doc, 0, crop_preset)
                    doc.close()

                    st.image(preview_img, caption=f"Preview: {first_file.name} (P√°gina 1) - Crop: {crop_preset}", use_container_width=True)
                    st.caption("‚¨ÜÔ∏è Esta √© a √°rea que a IA vai analisar em TODOS os desenhos")
                    st.warning("‚ö†Ô∏è **ATEN√á√ÉO:** Verifica se a TABELA DE REVIS√ïES est√° completamente vis√≠vel. Se n√£o estiver, ajusta o crop na barra lateral.")

                    col_val, col_alt = st.columns(2)
                    with col_val:
                        if st.button("‚úÖ Validar e Processar", type="primary", use_container_width=True, key="btn_validar"):
                            st.session_state.crop_validated = True
                            st.session_state.should_process = True
                            st.session_state.pending_tasks = uploaded_files
                            st.rerun()
                    with col_alt:
                        if st.button("üîÑ Alterar Crop", use_container_width=True, key="btn_alterar"):
                            st.info("üëà Ajusta a configura√ß√£o de crop na barra lateral e tenta novamente")

                elif file_ext in ['dwg', 'dxf'] and DWG_SUPPORT:
                    st.warning("‚ö†Ô∏è Preview de crop para DWG ainda n√£o implementado. A processar diretamente...")
                    st.session_state.crop_validated = True
                    st.session_state.should_process = True
                    st.session_state.pending_tasks = uploaded_files
                    st.rerun()
                else:
                    st.error(f"Tipo de ficheiro n√£o suportado: {file_ext}")

            except Exception as e:
                st.error(f"Erro ao gerar preview: {e}")
                if st.button("Continuar mesmo assim", key="btn_continuar"):
                    st.session_state.crop_validated = True
                    st.session_state.should_process = True
                    st.session_state.pending_tasks = uploaded_files
                    st.rerun()

    # PROCESSAMENTO PRINCIPAL (ap√≥s valida√ß√£o ou direto)
    # Usar pending_tasks em vez de uploaded_files para evitar perda ap√≥s rerun
    files_to_process = st.session_state.pending_tasks if st.session_state.should_process else None

    if st.session_state.should_process and files_to_process:
        if not api_key:
            st.error("‚ö†Ô∏è Falta a API Key na barra lateral!")
        else:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Pr√©-processamento: Extrair todas as p√°ginas/layouts
            all_tasks = []
            total_operations = 0

            for file in files_to_process:
                file_ext = file.name.lower().split('.')[-1]
                
                try:
                    if file_ext == 'pdf':
                        # Processar PDF
                        bytes_data = file.read()
                        doc = fitz.open(stream=bytes_data, filetype="pdf")

                        for page_num in range(doc.page_count):
                            display_name = f"{file.name} (P√°g. {page_num + 1})"
                            img = get_image_from_page(doc, page_num, crop_preset)

                            all_tasks.append({
                                "image": img,
                                "display_name": display_name,
                                "batch_type": batch_type.upper(),
                                "is_native": False
                            })
                            total_operations += 1

                        doc.close()
                        
                    elif file_ext in ['dwg', 'dxf'] and DWG_SUPPORT:
                        # Processar DWG/DXF com HYBRID WORKFLOW
                        status_text.text(f"A processar {file.name}...")
                        
                        # Guardar temporariamente (ezdxf precisa de ficheiro no disco)
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_ext}') as tmp:
                            tmp.write(file.read())
                            tmp_path = tmp.name
                        
                        try:
                            # Obter layouts (apenas Paper Space, Model Space √© ignorado)
                            layouts = get_dwg_layouts(tmp_path)

                            if not layouts:
                                st.warning(f"‚ö†Ô∏è **{file.name}**: Apenas cont√©m Model Space. Desenhos devem estar em Paper Space (Layout1, Layout2, etc). Ficheiro ignorado.")
                                logger.warning(f"DWG ignorado (s√≥ Model Space): {file.name}")
                                continue

                            status_text.text(f"Encontrados {len(layouts)} Paper Space layouts em {file.name}")
                            
                            for layout_idx, layout_name in enumerate(layouts):
                                try:
                                    # TENTATIVA 1: Extra√ß√£o Nativa (zero custo, instant)
                                    status_text.text(f"Tentando extra√ß√£o nativa de {file.name} (Layout: {layout_name})...")
                                    native_blocks = extract_dwg_native_blocks(tmp_path, layout_name)
                                    
                                    if native_blocks:
                                        # Sucesso! Adicionar todos os blocos encontrados
                                        for block_idx, block_data in enumerate(native_blocks):
                                            display_name = f"{file.name} (Layout: {layout_name}, Bloco {block_idx+1})"
                                            
                                            all_tasks.append({
                                                "native_data": block_data,  # Dados j√° extra√≠dos!
                                                "display_name": display_name,
                                                "batch_type": batch_type.upper(),
                                                "is_native": True
                                            })
                                            total_operations += 1
                                        
                                        logger.info(f"‚úÖ Extra√ß√£o nativa: {len(native_blocks)} blocos em {layout_name}")
                                    else:
                                        # FALLBACK: Rendering + Gemini (custo API)
                                        logger.warning(f"Sem blocos LEGENDA em {layout_name}, usando rendering + Gemini")
                                        display_name = f"{file.name} (Layout: {layout_name})"
                                        status_text.text(f"A renderizar {display_name} (fallback)...")
                                        
                                        img = get_image_from_dwg_layout(tmp_path, layout_name)
                                        
                                        all_tasks.append({
                                            "image": img,
                                            "display_name": display_name,
                                            "batch_type": batch_type.upper(),
                                            "is_native": False
                                        })
                                        total_operations += 1
                                    
                                except Exception as layout_error:
                                    st.warning(f"‚ö†Ô∏è Erro no layout '{layout_name}' de {file.name}: {str(layout_error)}")
                                    continue
                                    
                        except Exception as dwg_error:
                            st.error(f"‚ùå Erro ao processar {file.name}: {str(dwg_error)}")
                        finally:
                            # Limpar ficheiro tempor√°rio
                            try:
                                if os.path.exists(tmp_path):
                                    os.unlink(tmp_path)
                            except (FileNotFoundError, PermissionError, OSError) as e:
                                logger.warning(f"N√£o foi poss√≠vel eliminar ficheiro tempor√°rio {tmp_path}: {e}")
                                pass
                    
                except Exception as e:
                    st.error(f"Erro ao ler {file.name}: {e}")
            
            # Processamento Ass√≠ncrono em Paralelo (HYBRID: Native + Gemini)
            async def process_all_pages():
                """Processa todas as p√°ginas em paralelo com rate limiting."""
                # Configurar rate limiter e batch size baseado no modo
                if turbo_mode:
                    rate_limiter = RateLimiter(max_requests=1000, time_window=60)
                    batch_size = 50
                    logger.info("Modo TURBO ativo: 1000 req/min, batch 50")
                else:
                    rate_limiter = RateLimiter(max_requests=15, time_window=60)
                    batch_size = 5
                    logger.info("Modo Standard ativo: 15 req/min, batch 5")

                new_records = []

                # Separar tasks nativas (sem custo) de tasks de imagem (Gemini)
                native_tasks = [t for t in all_tasks if t.get("is_native", False)]
                gemini_tasks = [t for t in all_tasks if not t.get("is_native", False)]
                
                completed = 0
                
                # PROCESSAR TASKS NATIVAS (instant√¢neo, sem API calls)
                for task_data in native_tasks:
                    data = task_data["native_data"]
                    
                    record = {
                        "TIPO": data.get("tipo", task_data["batch_type"]),  # TIPO extra√≠do do DXF
                        "Num. Desenho": data.get("num_desenho", "N/A"),
                        "Titulo": data.get("titulo", "N/A"),
                        "1¬™ Emiss√£o": data.get("primeira_emissao", "-"),
                        "Revis√£o": data.get("revisao", ""),           # Vazio se sem revis√µes
                        "Data": data.get("data_revisao", ""),         # Vazio se sem revis√µes
                        "Descri√ß√£o": data.get("desc_revisao", ""),    # Vazio se sem revis√µes
                        "Ficheiro": task_data["display_name"],
                        "Obs": data.get("obs", ""),
                        "_source": "DXF"  # Flag interna para filtrar visualiza√ß√£o
                    }
                    
                    new_records.append(record)
                    completed += 1
                    progress_bar.progress(completed / total_operations)
                    status_text.text(f"‚úÖ Nativo: {data.get('num_desenho', 'N/A')} ({completed}/{total_operations})")
                
                # PROCESSAR TASKS GEMINI (ass√≠ncronas com rate limiting)
                if gemini_tasks:
                    async_tasks = []
                    for task_data in gemini_tasks:
                        async_tasks.append(
                            ask_gemini_async(
                                task_data["image"],
                                task_data["display_name"],
                                rate_limiter,
                                api_key
                            )
                        )
                    
                    for i in range(0, len(async_tasks), batch_size):
                        batch = async_tasks[i:i + batch_size]
                        
                        status_text.text(f"A processar batch Gemini {i//batch_size + 1} ({len(batch)} p√°ginas)...")
                        
                        # Executar batch em paralelo
                        results = await asyncio.gather(*batch, return_exceptions=True)
                        
                        # Processar resultados
                        for idx, result in enumerate(results):
                            task_idx = i + idx
                            task_info = gemini_tasks[task_idx]
                            
                            # Desempacotar resultado (data, tokens)
                            if isinstance(result, Exception):
                                data = {"error": str(result), "num_desenho": "ERRO", "titulo": task_info["display_name"]}
                                tokens = 0
                            elif isinstance(result, tuple):
                                data, tokens = result
                                st.session_state.total_tokens += tokens
                            else:
                                data = result
                                tokens = 0
                            
                            record = {
                                "TIPO": task_info["batch_type"],
                                "Num. Desenho": data.get("num_desenho", "N/A"),
                                "Titulo": data.get("titulo", "N/A"),
                                "1¬™ Emiss√£o": "-",                          # PDF n√£o tem este campo
                                "Revis√£o": data.get("revisao", "-"),
                                "Data": data.get("data", "-"),
                                "Descri√ß√£o": "-",                           # PDF n√£o tem este campo
                                "Ficheiro": task_info["display_name"],
                                "Obs": data.get("obs", ""),
                                "_source": "PDF"  # Flag interna
                            }
                            
                            if "error" in data:
                                record["Obs"] = f"Erro IA: {data['error']}"
                            
                            new_records.append(record)
                            completed += 1
                            progress_bar.progress(completed / total_operations)
                
                return new_records
            
            # Executar processamento ass√≠ncrono
            try:
                new_records = asyncio.run(process_all_pages())
                st.session_state.master_data.extend(new_records)
                status_text.success(f"‚úÖ Processado! ({len(new_records)} desenhos extra√≠dos)")

                # Resetar estados para pr√≥ximo lote
                st.session_state.crop_validated = False
                st.session_state.should_process = False
                st.session_state.pending_tasks = None

                # Limpar ficheiros carregados (for√ßa reset do uploader)
                st.session_state['uploader_key'] = st.session_state.get('uploader_key', 0) + 1

                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"Erro no processamento: {e}")
                st.session_state.crop_validated = False
                st.session_state.should_process = False
                st.session_state.pending_tasks = None

with col_view:
    st.subheader("2. Lista Completa")
    if len(st.session_state.master_data) > 0:
        df = pd.DataFrame(st.session_state.master_data)
        
        # PAINEL DE REORDENA√á√ÉO POR TIPO
        st.markdown("### üîÑ Reordenar por Tipo")
        
        tipos_unicos = sorted(df['TIPO'].unique().tolist())
        
        st.caption("Clica nos tipos pela ordem desejada (1¬∫, 2¬∫, 3¬∫...)")
        col_pills, col_btn = st.columns([4, 1])
        
        with col_pills:
            # Interface para definir ordem
            st.write("**Ordem atual:**", " ‚Üí ".join(st.session_state.ordem_customizada) if st.session_state.ordem_customizada else "Alfab√©tica")
            
            cols = st.columns(len(tipos_unicos))
            for idx, tipo in enumerate(tipos_unicos):
                with cols[idx]:
                    if st.button(tipo, key=f"tipo_{tipo}", use_container_width=True):
                        if tipo in st.session_state.ordem_customizada:
                            st.session_state.ordem_customizada.remove(tipo)
                        else:
                            st.session_state.ordem_customizada.append(tipo)
                        st.rerun()
        
        with col_btn:
            if st.button("üîÑ Reset", help="Voltar √† ordem alfab√©tica"):
                st.session_state.ordem_customizada = []
                st.rerun()
        
        # Aplicar ordena√ß√£o
        if st.session_state.ordem_customizada:
            # Usar ordem customizada
            ordem_completa = st.session_state.ordem_customizada + [t for t in tipos_unicos if t not in st.session_state.ordem_customizada]
            ordem_map = {tipo: idx for idx, tipo in enumerate(ordem_completa)}
            df['_ordem'] = df['TIPO'].map(ordem_map)
            df = df.sort_values(by=['_ordem', 'Num. Desenho'])
            df = df.drop('_ordem', axis=1)
        else:
            # Ordem alfab√©tica padr√£o
            if "Num. Desenho" in df.columns and "TIPO" in df.columns:
                df = df.sort_values(by=["TIPO", "Num. Desenho"])
        
        st.divider()
        
        # Detectar se tem registos DXF (extrac√ß√£o nativa)
        has_dxf = '_source' in df.columns and (df['_source'] == 'DXF').any()
        has_pdf = '_source' in df.columns and (df['_source'] == 'PDF').any()
        
        if has_dxf and not has_pdf:
            # VISUALIZA√á√ÉO DXF: Colunas espec√≠ficas, valores centrados, ordenar por n√∫mero
            df_display = df[['TIPO', 'Num. Desenho', '1¬™ Emiss√£o', 'Revis√£o', 'Data']].copy()
            df_display = df_display.sort_values(by='Num. Desenho')
            
            st.dataframe(
                df_display,
                use_container_width=True,
                column_config={
                    "TIPO": st.column_config.TextColumn("TIPO", width="medium"),
                    "Num. Desenho": st.column_config.TextColumn("N√∫mero de Desenho", width="medium"),
                    "1¬™ Emiss√£o": st.column_config.TextColumn("1¬™ Emiss√£o", width="small"),
                    "Revis√£o": st.column_config.TextColumn("Revis√£o", width="small"),
                    "Data": st.column_config.TextColumn("Data Revis√£o", width="small")
                },
                hide_index=True
            )
        elif has_pdf and not has_dxf:
            # VISUALIZA√á√ÉO PDF: Layout original (todas as colunas exceto _source)
            df_display = df.drop(columns=['_source'], errors='ignore')
            st.dataframe(
                df_display, 
                use_container_width=True,
                column_config={"Ficheiro": st.column_config.TextColumn("Origem"), "Obs": st.column_config.TextColumn("Obs", width="small")},
                hide_index=True
            )
        else:
            # MODO MISTO: Mostrar todas as colunas (exceto _source)
            df_display = df.drop(columns=['_source'], errors='ignore')
            st.dataframe(
                df_display,
                use_container_width=True,
                column_config={"Ficheiro": st.column_config.TextColumn("Origem"), "Obs": st.column_config.TextColumn("Obs", width="small")},
                hide_index=True
            )
        
        # BOT√ïES DE EXPORTA√á√ÉO
        st.markdown("### üì• Exportar")
        col_exp1, col_exp2, col_exp3 = st.columns(3)
        
        with col_exp1:
            # Exportar XLSX
            buffer_xlsx = io.BytesIO()
            with pd.ExcelWriter(buffer_xlsx, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='Lista Mestra JSJ')
                worksheet = writer.sheets['Lista Mestra JSJ']
                worksheet.set_column(0, 0, 15)  # TIPO
                worksheet.set_column(1, 1, 20)  # Num. Desenho
                worksheet.set_column(2, 2, 40)  # Titulo
                worksheet.set_column(3, 3, 10)  # Revis√£o
                worksheet.set_column(4, 4, 12)  # Data
                worksheet.set_column(5, 5, 30)  # Ficheiro
                worksheet.set_column(6, 6, 25)  # Obs
            
            st.download_button(
                "üìä Descarregar XLSX",
                data=buffer_xlsx.getvalue(),
                file_name="lista_desenhos_jsj.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        with col_exp2:
            # Exportar Markdown
            md_content = "# Lista de Desenhos JSJ\n\n"
            
            # Agrupar por TIPO
            for tipo in df['TIPO'].unique():
                df_tipo = df[df['TIPO'] == tipo]
                md_content += f"## {tipo}\n\n"
                md_content += "| Num. Desenho | T√≠tulo | Rev | Data | Ficheiro | Obs |\n"
                md_content += "|--------------|--------|-----|------|----------|-----|\n"
                
                for _, row in df_tipo.iterrows():
                    md_content += f"| {row['Num. Desenho']} | {row['Titulo']} | {row['Revis√£o']} | {row['Data']} | {row['Ficheiro']} | {row['Obs']} |\n"
                
                md_content += "\n"
            
            st.download_button(
                "üìù Descarregar MD",
                data=md_content,
                file_name="lista_desenhos_jsj.md",
                mime="text/markdown"
            )
        
        with col_exp3:
            # Exportar PDF
            pdf_buffer = create_pdf_export(df)
            
            st.download_button(
                "üìÑ Descarregar PDF",
                data=pdf_buffer.getvalue(),
                file_name="lista_desenhos_jsj.pdf",
                mime="application/pdf"
            )
    else:
        st.info("Define um 'Tipo' e carrega ficheiros.")